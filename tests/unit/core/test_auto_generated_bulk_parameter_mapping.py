"""Test parameter mapping for auto-generated bulk nodes."""

from unittest.mock import MagicMock, patch

import pytest
from dataflow.core.nodes import NodeGenerator


class TestAutoGeneratedBulkParameterMapping:
    """Test that auto-generated bulk nodes properly handle parameter mapping."""

    def setup_method(self):
        """Set up test with node generator directly."""
        # Create a mock DataFlow instance
        mock_dataflow = MagicMock()
        mock_dataflow.config.security.multi_tenant = False
        mock_dataflow._tenant_context = {}

        # Create node generator directly
        self.node_generator = NodeGenerator(mock_dataflow)

        # Define test fields
        test_fields = {"name": str, "email": str, "active": bool}

        # Generate nodes directly
        nodes = self.node_generator.generate_bulk_nodes("User", test_fields)
        self.bulk_create_node = nodes["UserBulkCreateNode"]
        self.bulk_update_node = nodes["UserBulkUpdateNode"]
        self.bulk_delete_node = nodes["UserBulkDeleteNode"]
        self.bulk_upsert_node = nodes["UserBulkUpsertNode"]

    def test_bulk_create_parameter_definitions(self):
        """Test that bulk create node has proper parameter definitions."""
        node_instance = self.bulk_create_node()
        params = node_instance.get_parameters()

        # Check data parameter has auto_map_from
        assert "data" in params
        data_param = params["data"]
        assert data_param.auto_map_from == ["records", "rows", "documents"]

        # Check other expected parameters exist
        assert "batch_size" in params
        assert "conflict_resolution" in params

    def test_bulk_create_with_data_parameter(self):
        """Test bulk create works with 'data' parameter."""
        node_instance = self.bulk_create_node()

        test_data = [
            {"name": "Alice", "email": "alice@example.com"},
            {"name": "Bob", "email": "bob@example.com"},
        ]

        # This should work (existing behavior)
        result = node_instance.run(data=test_data)

        # In memory mode, we expect mock-like behavior
        assert isinstance(result, dict)
        # Since we're using in-memory database, exact results depend on implementation

    def test_bulk_create_with_records_parameter(self):
        """Test bulk create works with 'records' parameter via auto_map_from."""
        node_instance = self.bulk_create_node()

        test_records = [
            {"name": "Charlie", "email": "charlie@example.com"},
            {"name": "Diana", "email": "diana@example.com"},
        ]

        # This should now work thanks to auto_map_from
        result = node_instance.run(records=test_records)

        # In memory mode, we expect mock-like behavior
        assert isinstance(result, dict)

    def test_bulk_create_with_rows_parameter(self):
        """Test bulk create works with 'rows' parameter via auto_map_from."""
        node_instance = self.bulk_create_node()

        test_rows = [
            {"name": "Eve", "email": "eve@example.com"},
            {"name": "Frank", "email": "frank@example.com"},
        ]

        # This should work via auto_map_from
        result = node_instance.run(rows=test_rows)

        assert isinstance(result, dict)

    def test_bulk_create_with_documents_parameter(self):
        """Test bulk create works with 'documents' parameter via auto_map_from."""
        node_instance = self.bulk_create_node()

        test_documents = [
            {"name": "Grace", "email": "grace@example.com"},
            {"name": "Henry", "email": "henry@example.com"},
        ]

        # This should work via auto_map_from
        result = node_instance.run(documents=test_documents)

        assert isinstance(result, dict)

    def test_bulk_update_parameter_mapping(self):
        """Test bulk update node parameter mapping."""
        node_instance = self.bulk_update_node()
        params = node_instance.get_parameters()

        # Check data parameter has auto_map_from for update operations
        assert "data" in params
        data_param = params["data"]
        assert data_param.auto_map_from == ["records", "rows", "documents"]

    def test_bulk_delete_parameter_mapping(self):
        """Test bulk delete node parameter mapping."""
        node_instance = self.bulk_delete_node()
        params = node_instance.get_parameters()

        # Check data parameter has auto_map_from for delete operations
        assert "data" in params
        data_param = params["data"]
        assert data_param.auto_map_from == ["records", "rows", "documents"]

    def test_bulk_upsert_parameter_mapping(self):
        """Test bulk upsert node parameter mapping."""
        node_instance = self.bulk_upsert_node()
        params = node_instance.get_parameters()

        # Check data parameter has auto_map_from for upsert operations
        assert "data" in params
        data_param = params["data"]
        assert data_param.auto_map_from == ["records", "rows", "documents"]

    def test_parameter_precedence(self):
        """Test that 'data' parameter takes precedence when multiple are provided."""
        node_instance = self.bulk_create_node()

        # Provide both data and records - data should take precedence
        data_records = [{"name": "Data User", "email": "data@example.com"}]
        records_records = [{"name": "Records User", "email": "records@example.com"}]

        # This tests the SDK's parameter resolution system
        # The exact behavior depends on SDK implementation
        result = node_instance.run(data=data_records, records=records_records)

        assert isinstance(result, dict)

    def test_validate_inputs_called(self):
        """Test that validate_inputs is called and handles parameter mapping."""
        node_instance = self.bulk_create_node()

        # Mock validate_inputs to verify it's called
        original_validate = node_instance.validate_inputs
        call_count = 0

        def mock_validate(**kwargs):
            nonlocal call_count
            call_count += 1
            return original_validate(**kwargs)

        node_instance.validate_inputs = mock_validate

        test_records = [{"name": "Test", "email": "test@example.com"}]
        node_instance.run(records=test_records)

        # Verify validate_inputs was called
        assert call_count == 1

    def test_consistency_with_dedicated_bulk_nodes(self):
        """Test that auto-generated nodes match dedicated bulk node parameter definitions."""
        # Import a dedicated bulk node for comparison
        from dataflow.nodes.bulk_create import BulkCreateNode

        dedicated_node = BulkCreateNode(table_name="test_table")
        dedicated_params = dedicated_node.get_parameters()

        auto_generated_node = self.bulk_create_node()
        auto_generated_params = auto_generated_node.get_parameters()

        # Check data parameter consistency
        assert "data" in dedicated_params and "data" in auto_generated_params

        # Both should have the same auto_map_from configuration
        dedicated_data_param = dedicated_params["data"]
        auto_generated_data_param = auto_generated_params["data"]

        assert (
            dedicated_data_param.auto_map_from
            == auto_generated_data_param.auto_map_from
        )
        assert dedicated_data_param.auto_map_from == ["records", "rows", "documents"]

    def test_all_bulk_operations_have_consistent_mapping(self):
        """Test that all bulk operations have consistent parameter mapping."""
        operations = {
            "create": self.bulk_create_node,
            "update": self.bulk_update_node,
            "delete": self.bulk_delete_node,
            "upsert": self.bulk_upsert_node,
        }

        for operation_name, node_class in operations.items():
            node_instance = node_class()
            params = node_instance.get_parameters()

            # All bulk operations should have data parameter with auto_map_from
            assert "data" in params, f"{operation_name} missing data parameter"

            data_param = params["data"]
            assert hasattr(
                data_param, "auto_map_from"
            ), f"{operation_name} missing auto_map_from"
            assert data_param.auto_map_from == [
                "records",
                "rows",
                "documents",
            ], f"{operation_name} has incorrect auto_map_from: {data_param.auto_map_from}"

    def test_empty_data_handling(self):
        """Test handling of empty data with different parameter names."""
        node_instance = self.bulk_create_node()

        # Test with empty lists using different parameter names
        test_cases = [{"data": []}, {"records": []}, {"rows": []}, {"documents": []}]

        for test_case in test_cases:
            result = node_instance.run(**test_case)
            # Should handle empty data gracefully
            assert isinstance(result, dict)
