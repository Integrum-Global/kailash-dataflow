#!/usr/bin/env python3
"""
Error Recovery Tests for NOT NULL Column Addition System

Tests comprehensive error handling, recovery mechanisms, and failure scenarios
in the NOT NULL column addition functionality.

This test suite ensures the system gracefully handles all failure modes.
"""

import asyncio
from datetime import datetime
from unittest.mock import AsyncMock, MagicMock, Mock, patch

import pytest
from dataflow.migrations.constraint_validator import ConstraintValidator
from dataflow.migrations.default_strategies import DefaultValueStrategyManager
from dataflow.migrations.not_null_handler import (
    AdditionExecutionResult,
    AdditionResult,
    ColumnDefinition,
    DefaultValueType,
    NotNullAdditionPlan,
    NotNullColumnHandler,
    ValidationResult,
)


def create_mock_connection():
    """Create a mock connection with transaction support."""
    mock_connection = AsyncMock()

    # Create a proper async context manager class
    class MockTransaction:
        async def __aenter__(self):
            return None

        async def __aexit__(self, exc_type, exc_val, exc_tb):
            return None

    # Make transaction() return the context manager directly, not a coroutine
    mock_connection.transaction = Mock(return_value=MockTransaction())

    return mock_connection


class TestNetworkFailures:
    """Test handling of network-related failures."""

    def setup_method(self):
        """Set up test fixtures."""
        self.handler = NotNullColumnHandler()

    @pytest.mark.asyncio
    async def test_connection_loss_during_planning(self):
        """Test handling of connection loss during planning phase."""
        mock_connection = create_mock_connection()

        # Simulate connection loss after initial queries
        call_count = {"count": 0}

        async def mock_fetchval(query, *args):
            call_count["count"] += 1
            if call_count["count"] > 1:
                raise ConnectionResetError("Connection lost to database")
            return 1000  # Row count

        mock_connection.fetchval = mock_fetchval
        mock_connection.fetch.side_effect = ConnectionResetError("Connection lost")

        with patch.object(
            self.handler, "_get_connection", return_value=mock_connection
        ):
            column = ColumnDefinition(
                name="test_col", data_type="VARCHAR(50)", default_value="test"
            )

            with pytest.raises(ConnectionResetError):
                await self.handler.plan_not_null_addition("test_table", column)

    @pytest.mark.asyncio
    async def test_connection_loss_during_execution(self):
        """Test handling of connection loss during execution."""
        mock_connection = create_mock_connection()
        mock_connection.fetchval.return_value = 1000
        mock_connection.fetch.return_value = []

        # Simulate connection loss during ALTER TABLE
        mock_connection.execute.side_effect = ConnectionResetError(
            "Connection lost during ALTER"
        )

        # Transaction context is already properly configured by create_mock_connection()

        with patch.object(
            self.handler, "_get_connection", return_value=mock_connection
        ):
            column = ColumnDefinition(
                name="test_col", data_type="VARCHAR(50)", default_value="test"
            )

            plan = NotNullAdditionPlan(
                table_name="test_table", column=column, execution_strategy="single_ddl"
            )

            result = await self.handler.execute_not_null_addition(plan)

            assert result.result == AdditionResult.ROLLBACK_REQUIRED
            assert result.rollback_executed is True
            assert "Connection lost" in result.error_message

    @pytest.mark.asyncio
    async def test_intermittent_network_failures(self):
        """Test handling of intermittent network failures with retry logic."""
        mock_connection = create_mock_connection()

        # Simulate intermittent failures
        attempt_count = {"count": 0}

        async def mock_execute(query):
            attempt_count["count"] += 1
            if attempt_count["count"] <= 2:
                raise ConnectionError("Temporary network issue")
            return None  # Success on third attempt

        mock_connection.execute = mock_execute
        mock_connection.fetchval.return_value = 100
        mock_connection.fetch.return_value = []

        # Transaction context is already properly configured by create_mock_connection()

        with patch.object(
            self.handler, "_get_connection", return_value=mock_connection
        ):
            column = ColumnDefinition(
                name="retry_col", data_type="VARCHAR(50)", default_value="test"
            )

            plan = NotNullAdditionPlan(
                table_name="test_table", column=column, execution_strategy="single_ddl"
            )

            # Should handle intermittent failures
            result = await self.handler.execute_not_null_addition(plan)

            # Depending on retry implementation
            assert result.result in [
                AdditionResult.SUCCESS,
                AdditionResult.ROLLBACK_REQUIRED,
            ]


class TestResourceExhaustion:
    """Test handling of resource exhaustion scenarios."""

    def setup_method(self):
        """Set up test fixtures."""
        self.handler = NotNullColumnHandler()
        self.manager = DefaultValueStrategyManager()

    @pytest.mark.asyncio
    async def test_memory_exhaustion_during_batched_update(self):
        """Test handling of memory exhaustion during large batched updates."""
        mock_connection = create_mock_connection()
        mock_connection.fetchval.return_value = 10000000  # Very large table
        mock_connection.fetch.return_value = []

        # Simulate memory error during batch processing
        batch_count = {"count": 0}

        async def mock_fetchval_batch(query, *args):
            if "WITH batch AS" in query:
                batch_count["count"] += 1
                if batch_count["count"] > 5:
                    raise MemoryError("Out of memory processing large batch")
                return 10000  # Rows updated
            return 10000000

        mock_connection.fetchval = mock_fetchval_batch
        mock_connection.execute = AsyncMock()

        # Transaction context is already properly configured by create_mock_connection()

        with patch.object(
            self.handler, "_get_connection", return_value=mock_connection
        ):
            column = ColumnDefinition(
                name="large_col",
                data_type="TEXT",
                default_expression="REPEAT('x', 1000000)",  # Large value
                default_type=DefaultValueType.COMPUTED,
            )

            plan = NotNullAdditionPlan(
                table_name="huge_table",
                column=column,
                execution_strategy="batched_update",
                batch_size=10000,
            )

            result = await self.handler.execute_not_null_addition(plan)

            assert result.result == AdditionResult.ROLLBACK_REQUIRED
            assert "memory" in result.error_message.lower()

    @pytest.mark.asyncio
    async def test_disk_space_exhaustion(self):
        """Test handling of disk space exhaustion."""
        mock_connection = create_mock_connection()
        mock_connection.fetchval.return_value = 1000000
        mock_connection.fetch.return_value = []

        # Simulate disk space error
        mock_connection.execute.side_effect = Exception(
            "could not extend file: No space left on device"
        )

        # Transaction context is already properly configured by create_mock_connection()

        with patch.object(
            self.handler, "_get_connection", return_value=mock_connection
        ):
            column = ColumnDefinition(
                name="disk_col", data_type="TEXT", default_value="x" * 1000
            )

            plan = NotNullAdditionPlan(
                table_name="test_table", column=column, execution_strategy="single_ddl"
            )

            result = await self.handler.execute_not_null_addition(plan)

            assert result.result == AdditionResult.ROLLBACK_REQUIRED
            assert "space" in result.error_message.lower()

    @pytest.mark.asyncio
    async def test_connection_pool_exhaustion(self):
        """Test handling of connection pool exhaustion."""
        # Simulate connection pool exhaustion
        attempt_count = {"count": 0}

        async def mock_get_connection():
            attempt_count["count"] += 1
            if attempt_count["count"] > 2:
                raise Exception(
                    "Connection pool exhausted: timeout waiting for connection"
                )
            mock_conn = create_mock_connection()
            mock_conn.fetchval.return_value = 100
            mock_conn.fetch.return_value = []
            mock_conn.execute = AsyncMock()
            return mock_conn

        with patch.object(
            self.handler, "_get_connection", side_effect=mock_get_connection
        ):
            column = ColumnDefinition(
                name="pool_col", data_type="VARCHAR(50)", default_value="test"
            )

            # Try multiple operations
            tasks = []
            for i in range(5):
                plan = NotNullAdditionPlan(
                    table_name=f"table_{i}",
                    column=column,
                    execution_strategy="single_ddl",
                )
                tasks.append(self.handler.validate_addition_safety(plan))

            results = await asyncio.gather(*tasks, return_exceptions=True)

            # Some should fail due to pool exhaustion
            failures = [r for r in results if isinstance(r, Exception)]
            assert len(failures) > 0
            assert any("pool exhausted" in str(f) for f in failures)


class TestTransactionFailures:
    """Test handling of transaction-related failures."""

    def setup_method(self):
        """Set up test fixtures."""
        self.handler = NotNullColumnHandler()

    @pytest.mark.asyncio
    async def test_transaction_timeout(self):
        """Test handling of transaction timeouts."""
        mock_connection = create_mock_connection()
        mock_connection.fetchval.return_value = 1000
        mock_connection.fetch.return_value = []

        # Simulate transaction timeout
        async def mock_execute_slow(query):
            await asyncio.sleep(2)  # Simulate slow operation
            raise asyncio.TimeoutError("Transaction timeout")

        mock_connection.execute = mock_execute_slow

        # Transaction context is already properly configured by create_mock_connection()

        with patch.object(
            self.handler, "_get_connection", return_value=mock_connection
        ):
            column = ColumnDefinition(
                name="timeout_col", data_type="VARCHAR(50)", default_value="test"
            )

            plan = NotNullAdditionPlan(
                table_name="test_table",
                column=column,
                execution_strategy="single_ddl",
                timeout_seconds=1,
            )

            result = await self.handler.execute_not_null_addition(plan)

            assert result.result == AdditionResult.ROLLBACK_REQUIRED
            assert "timeout" in result.error_message.lower()

    @pytest.mark.asyncio
    async def test_deadlock_detection(self):
        """Test handling of deadlock situations."""
        mock_connection = create_mock_connection()
        mock_connection.fetchval.return_value = 1000
        mock_connection.fetch.return_value = []

        # Simulate deadlock error
        mock_connection.execute.side_effect = Exception("deadlock detected")

        # Transaction context is already properly configured by create_mock_connection()

        with patch.object(
            self.handler, "_get_connection", return_value=mock_connection
        ):
            column = ColumnDefinition(
                name="deadlock_col", data_type="VARCHAR(50)", default_value="test"
            )

            plan = NotNullAdditionPlan(
                table_name="test_table", column=column, execution_strategy="single_ddl"
            )

            result = await self.handler.execute_not_null_addition(plan)

            assert result.result == AdditionResult.ROLLBACK_REQUIRED
            assert "deadlock" in result.error_message.lower()

    @pytest.mark.asyncio
    async def test_serialization_failure(self):
        """Test handling of serialization failures."""
        mock_connection = create_mock_connection()
        mock_connection.fetchval.return_value = 1000
        mock_connection.fetch.return_value = []

        # Simulate serialization failure
        attempt_count = {"count": 0}

        async def mock_execute(query):
            attempt_count["count"] += 1
            if attempt_count["count"] <= 1:
                raise Exception("could not serialize access due to concurrent update")
            return None

        mock_connection.execute = mock_execute

        # Transaction context is already properly configured by create_mock_connection()

        with patch.object(
            self.handler, "_get_connection", return_value=mock_connection
        ):
            column = ColumnDefinition(
                name="serial_col", data_type="VARCHAR(50)", default_value="test"
            )

            plan = NotNullAdditionPlan(
                table_name="test_table", column=column, execution_strategy="single_ddl"
            )

            result = await self.handler.execute_not_null_addition(plan)

            # Should handle serialization failure
            assert result.result in [
                AdditionResult.SUCCESS,
                AdditionResult.ROLLBACK_REQUIRED,
            ]


class TestPartialFailures:
    """Test handling of partial failure scenarios."""

    def setup_method(self):
        """Set up test fixtures."""
        self.handler = NotNullColumnHandler()

    @pytest.mark.asyncio
    async def test_partial_batch_failure(self):
        """Test handling when some batches succeed but others fail."""
        mock_connection = create_mock_connection()
        mock_connection.fetchval.return_value = 10000
        mock_connection.fetch.return_value = []
        mock_connection.execute = AsyncMock()

        # Simulate partial batch failure
        batch_count = {"count": 0}

        async def mock_fetchval_batch(query, *args):
            if "WITH batch AS" in query:
                batch_count["count"] += 1
                if batch_count["count"] == 3:
                    raise Exception("Batch 3 failed: unique constraint violation")
                elif batch_count["count"] > 5:
                    return None  # No more rows
                return 1000  # Rows updated
            return 10000

        mock_connection.fetchval = mock_fetchval_batch

        # Transaction context is already properly configured by create_mock_connection()

        with patch.object(
            self.handler, "_get_connection", return_value=mock_connection
        ):
            column = ColumnDefinition(
                name="partial_col",
                data_type="VARCHAR(50)",
                default_expression="CASE WHEN id % 2 = 0 THEN 'even' ELSE 'odd' END",
                default_type=DefaultValueType.COMPUTED,
            )

            plan = NotNullAdditionPlan(
                table_name="test_table",
                column=column,
                execution_strategy="batched_update",
                batch_size=1000,
            )

            result = await self.handler.execute_not_null_addition(plan)

            # Should rollback on partial failure
            assert result.result == AdditionResult.ROLLBACK_REQUIRED
            assert "Batch 3 failed" in result.error_message

    @pytest.mark.asyncio
    async def test_constraint_violation_after_partial_success(self):
        """Test handling when constraint violation occurs after partial success."""
        mock_connection = create_mock_connection()
        mock_connection.fetchval.return_value = 1000
        mock_connection.fetch.return_value = []

        # Track execution steps
        execution_steps = []

        async def mock_execute(query):
            if "ADD COLUMN" in query:
                execution_steps.append("ADD_COLUMN")
                return None
            elif "UPDATE" in query:
                execution_steps.append("UPDATE")
                return None
            elif "ALTER COLUMN" in query and "SET NOT NULL" in query:
                execution_steps.append("SET_NOT_NULL")
                # Fail at this step
                raise Exception("column contains null values")
            return None

        mock_connection.execute = mock_execute

        # Transaction context is already properly configured by create_mock_connection()

        with patch.object(
            self.handler, "_get_connection", return_value=mock_connection
        ):
            column = ColumnDefinition(
                name="constrained_col",
                data_type="VARCHAR(50)",
                default_expression="NULL",  # Will cause constraint violation
                default_type=DefaultValueType.COMPUTED,
            )

            plan = NotNullAdditionPlan(
                table_name="test_table",
                column=column,
                execution_strategy="batched_update",
            )

            result = await self.handler.execute_not_null_addition(plan)

            assert result.result == AdditionResult.ROLLBACK_REQUIRED
            assert "null values" in result.error_message.lower()
            # Verify partial execution occurred
            assert "ADD_COLUMN" in execution_steps


class TestRecoveryMechanisms:
    """Test recovery and rollback mechanisms."""

    def setup_method(self):
        """Set up test fixtures."""
        self.handler = NotNullColumnHandler()

    @pytest.mark.asyncio
    async def test_rollback_after_failure(self):
        """Test proper rollback after execution failure."""
        mock_connection = create_mock_connection()
        mock_connection.fetchval.return_value = 1000
        mock_connection.fetch.return_value = []

        # Track rollback actions
        rollback_actions = []

        async def mock_execute(query):
            if "DROP COLUMN" in query:
                rollback_actions.append("DROP_COLUMN")
            elif "ALTER TABLE" in query:
                raise Exception("Execution failed")
            return None

        mock_connection.execute = mock_execute

        # Track rollback state by overriding the transaction mock from create_mock_connection()
        rollback_called = {"called": False}

        async def mock_exit(exc_type, exc_val, exc_tb):
            if exc_type is not None:
                rollback_called["called"] = True
            return None

        # Replace the __aexit__ method while keeping the transaction as an async context manager
        mock_connection.transaction.return_value.__aexit__ = mock_exit

        with patch.object(
            self.handler, "_get_connection", return_value=mock_connection
        ):
            column = ColumnDefinition(
                name="rollback_col", data_type="VARCHAR(50)", default_value="test"
            )

            plan = NotNullAdditionPlan(
                table_name="test_table",
                column=column,
                execution_strategy="single_ddl",
                rollback_on_failure=True,
            )

            result = await self.handler.execute_not_null_addition(plan)

            assert result.result == AdditionResult.ROLLBACK_REQUIRED
            assert result.rollback_executed is True
            assert rollback_called["called"] is True

    @pytest.mark.asyncio
    async def test_savepoint_recovery(self):
        """Test recovery using savepoints."""
        mock_connection = create_mock_connection()
        mock_connection.fetchval.return_value = 1000
        mock_connection.fetch.return_value = []

        # Track savepoint operations
        savepoint_ops = []

        async def mock_execute(query):
            if "SAVEPOINT" in query:
                savepoint_ops.append("SAVEPOINT")
            elif "RELEASE SAVEPOINT" in query:
                savepoint_ops.append("RELEASE")
            elif "ROLLBACK TO SAVEPOINT" in query:
                savepoint_ops.append("ROLLBACK_TO")
            elif "ALTER TABLE" in query and "batch_2" in query:
                raise Exception("Batch 2 failed")
            return None

        mock_connection.execute = mock_execute

        with patch.object(
            self.handler, "_get_connection", return_value=mock_connection
        ):
            # Simulate handler using savepoints
            with patch.object(self.handler, "_use_savepoints", True):
                column = ColumnDefinition(
                    name="savepoint_col", data_type="VARCHAR(50)", default_value="test"
                )

                plan = NotNullAdditionPlan(
                    table_name="test_table",
                    column=column,
                    execution_strategy="batched_update",
                )

                result = await self.handler.execute_not_null_addition(plan)

                # Should use savepoints for recovery if implemented
                assert result.result in [
                    AdditionResult.SUCCESS,
                    AdditionResult.ROLLBACK_REQUIRED,
                ]

    @pytest.mark.asyncio
    async def test_idempotent_recovery(self):
        """Test that recovery operations are idempotent."""
        mock_connection = create_mock_connection()

        # Track operations
        operations = []

        async def mock_fetchval(query, *args):
            if "EXISTS" in query and "column_name" in query:
                # Column exists after first attempt
                return len(operations) > 0
            return 1000

        async def mock_execute(query):
            operations.append(query)
            if "ALTER TABLE" in query and len(operations) == 1:
                raise Exception("First attempt failed")
            return None

        mock_connection.fetchval = mock_fetchval
        mock_connection.execute = mock_execute
        mock_connection.fetch.return_value = []

        with patch.object(
            self.handler, "_get_connection", return_value=mock_connection
        ):
            column = ColumnDefinition(
                name="idempotent_col", data_type="VARCHAR(50)", default_value="test"
            )

            plan = NotNullAdditionPlan(
                table_name="test_table", column=column, execution_strategy="single_ddl"
            )

            # First attempt fails
            result1 = await self.handler.execute_not_null_addition(plan)
            assert result1.result == AdditionResult.ROLLBACK_REQUIRED

            # Second attempt should handle existing partial state
            result2 = await self.handler.validate_addition_safety(plan)
            assert result2.is_safe is False  # Column already exists


class TestErrorPropagation:
    """Test proper error propagation and logging."""

    def setup_method(self):
        """Set up test fixtures."""
        self.handler = NotNullColumnHandler()

    @pytest.mark.asyncio
    async def test_error_message_preservation(self):
        """Test that error messages are properly preserved and propagated."""
        mock_connection = create_mock_connection()
        mock_connection.fetchval.return_value = 1000
        mock_connection.fetch.return_value = []

        original_error = "DETAIL: Key (email)=(test@example.com) already exists."
        mock_connection.execute.side_effect = Exception(
            f"duplicate key value violates unique constraint\n{original_error}"
        )

        # Transaction context is already properly configured by create_mock_connection()

        with patch.object(
            self.handler, "_get_connection", return_value=mock_connection
        ):
            column = ColumnDefinition(
                name="unique_col",
                data_type="VARCHAR(50)",
                default_value="test@example.com",
                unique=True,
            )

            plan = NotNullAdditionPlan(
                table_name="test_table", column=column, execution_strategy="single_ddl"
            )

            result = await self.handler.execute_not_null_addition(plan)

            assert result.result == AdditionResult.ROLLBACK_REQUIRED
            assert "duplicate key" in result.error_message
            assert "already exists" in result.error_message

    @pytest.mark.asyncio
    async def test_nested_error_handling(self):
        """Test handling of nested errors."""
        mock_connection = create_mock_connection()

        # Create nested error scenario
        async def mock_get_connection():
            try:
                raise ConnectionError("Cannot connect to database")
            except ConnectionError as e:
                raise Exception(f"Connection manager error: {e}") from e

        with patch.object(
            self.handler, "_get_connection", side_effect=mock_get_connection
        ):
            column = ColumnDefinition(
                name="nested_col", data_type="VARCHAR(50)", default_value="test"
            )

            with pytest.raises(Exception) as exc_info:
                await self.handler.plan_not_null_addition("test_table", column)

            assert "Connection manager error" in str(exc_info.value)
            assert "Cannot connect" in str(exc_info.value)

    def test_error_categorization(self):
        """Test that errors are properly categorized."""
        errors = [
            ("Connection refused", "network"),
            ("No space left on device", "resource"),
            ("deadlock detected", "concurrency"),
            ("permission denied", "permission"),
            ("syntax error", "validation"),
            ("timeout", "timeout"),
        ]

        for error_msg, expected_category in errors:
            # This would test an error categorization method if implemented
            # For now, just verify the error messages are distinct
            assert error_msg != expected_category
            assert len(error_msg) > 0


if __name__ == "__main__":
    pytest.main([__file__, "-v", "--tb=short"])
