[pytest]
# DataFlow Test Configuration

# Python path (required for imports)
pythonpath = src

# Test discovery
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*

# Markers
markers =
    unit: Unit tests (fast, mocked, no external dependencies)
    integration: Integration tests (requires Docker services)
    e2e: End-to-end tests (complete user workflows)
    critical: Critical functionality that must pass
    slow: Tests that take > 10 seconds
    requires_postgres: Test requires PostgreSQL
    requires_mysql: Test requires MySQL
    requires_redis: Test requires Redis
    requires_docker: Test requires Docker services
    performance: Performance-related tests
    tier1: Unit tests (fast, no external dependencies)
    tier2: Integration tests (requires Docker services)
    tier3: End-to-end tests (complete user workflows)
    tdd: TDD-enhanced tests with savepoint isolation (<100ms target)
    postgresql: Tests for PostgreSQL database
    sqlite: Tests for SQLite database
    bug_reproduction: Bug reproduction tests (minimal failing examples)
    bug_investigation: Bug investigation tests (hypothesis validation)

# Test output
addopts =
    -v
    --strict-markers
    --tb=short
    --disable-warnings
    -p no:warnings

# Async support
asyncio_mode = auto
asyncio_default_fixture_loop_scope = function
asyncio_default_test_loop_scope = function

# Coverage options (when run with pytest-cov)
[coverage:run]
source = apps/kailash-dataflow
omit =
    */tests/*
    */test_*
    */__pycache__/*

[coverage:report]
exclude_lines =
    pragma: no cover
    def __repr__
    if self.debug:
    if settings.DEBUG
    raise AssertionError
    raise NotImplementedError
    if 0:
    if __name__ == .__main__.:
